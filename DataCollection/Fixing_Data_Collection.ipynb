{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In retrospect I should have written the .py scripts and then used .ipynb files to execute them. I'm going to try that here.\n",
    "\n",
    "Except the problem is that you have to reload the thing here if you make some changes... that's why I didn't do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import exp\n",
    "from textwrap import wrap\n",
    "import requests\n",
    "import pickle\n",
    "from requests.adapters import HTTPAdapter\n",
    "import logging\n",
    "import traceback\n",
    "from inspect import currentframe, getframeinfo\n",
    "import re\n",
    "import time\n",
    "import urllib3\n",
    "from Stitch_Dict import stitch_dict\n",
    "from Stitch_Dict import select_data\n",
    "import pathlib\n",
    "cwd = pathlib.Path.cwd()\n",
    "from GData import NormalData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines multiple pkl files into one master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch_dict(cwd.parent / \"Data_Files\" / \"Fly\" / \"Temp\", cwd.parent / \"Data_Files\" / \"Fly\" / \"Temp\" / \"Fly.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selects a portion (or all) of that data and creates data sets. Be sure to point this script to that master pkl file. Also, turn histogram method off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Anti_Data exists, and if not creating it.\n",
      "Loading data from d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Anitsense_Investigation.pkl\n",
      "Selecting 25000 random keys\n",
      "Creating two seperate datasets from the previously selected data\n",
      "Cleaning dataset 1\n",
      "Writing Dataset 1 to d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Anti_Data/Data_Set_1_cleaned_dict.pkl\n",
      "Converting Dataset 1 to a dataframe\n",
      "Writing converted Dataset 1 to d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Anti_Data/Data_Set_1_frame.pkl\n",
      "Cleaning dataset 2\n",
      "Writing Dataset 2 to d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Anti_Data/Data_Set_2_cleaned_dict.pkl\n",
      "Converting Dataset 2 to a dataframe\n",
      "Writing converted Dataset 2 to d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Anti_Data/Data_Set_2_frame.pkl\n"
     ]
    }
   ],
   "source": [
    "select_data(cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Anitsense_Investigation.pkl\", cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Anti_Data\", histogram_method = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Sense_Data exists, and if not creating it.\n",
      "Loading data from d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Sense_Investigation.pkl\n",
      "Selecting 25000 random keys\n",
      "Creating two seperate datasets from the previously selected data\n",
      "Cleaning dataset 1\n",
      "Writing Dataset 1 to d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Sense_Data/Data_Set_1_cleaned_dict.pkl\n",
      "Converting Dataset 1 to a dataframe\n",
      "Writing converted Dataset 1 to d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Sense_Data/Data_Set_1_frame.pkl\n",
      "Cleaning dataset 2\n",
      "Writing Dataset 2 to d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Sense_Data/Data_Set_2_cleaned_dict.pkl\n",
      "Converting Dataset 2 to a dataframe\n",
      "Writing converted Dataset 2 to d:\\Coding\\Thesis\\Data_Files\\Primates\\Genetics\\Homo_sapiens\\Sense_Data/Data_Set_2_frame.pkl\n"
     ]
    }
   ],
   "source": [
    "select_data(cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Sense_Investigation.pkl\", cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Sense_Data\", histogram_method = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow merge of cleaned dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Cleaned_Data\" / \"Data_set_1_cleaned_dict.pkl\", \"rb\") as file:\n",
    "    cleaned_1 = pickle.load(file)\n",
    "\n",
    "with open(cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Cleaned_Data\" / \"Data_set_2_cleaned_dict.pkl\", \"rb\") as file:\n",
    "    cleaned_2 = pickle.load(file)\n",
    "\n",
    "cleaned = cleaned_1 | cleaned_2\n",
    "\n",
    "with open(cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Cleaned_Data\" / \"Cleaned_Data_dict.pkl\", \"wb\") as file:\n",
    "    pickle.dump(cleaned, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for creating data to compare to cancer data.\n",
    "\n",
    "Also useful for creating a lazy dataset for time embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalData(cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Cleaned_Data\" / \"Cleaned_Data_dict.pkl\",\n",
    "           cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Exon_Intron_Data\" / \"Exon_v2.xlsx\",\n",
    "           cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Exon_Intron_Data\" / \"Intron_v2.xlsx\",\n",
    "           min_length = 20)\n",
    "# path = cwd.parent / \"Data_Files\" / \"Primates\" / \"Genetics\" / \"Homo_sapiens\" / \"Exon_Intron_Data\" / \"Exon.xlsx\"\n",
    "# path.parent.mkdir(parents=True, exist_ok=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
