Seed: 5798011

Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 64, 64, 4)]       0         
                                                                 
 conv2d (Conv2D)             (None, 64, 64, 64)        320       
                                                                 
 dropout (Dropout)           (None, 64, 64, 64)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 64, 64, 64)        4160      
                                                                 
 dropout_1 (Dropout)         (None, 64, 64, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 64, 64, 64)        4160      
                                                                 
 dropout_2 (Dropout)         (None, 64, 64, 64)        0         
                                                                 
 flatten (Flatten)           (None, 262144)            0         
                                                                 
 dense (Dense)               (None, 2)                 524290    
                                                                 
=================================================================
Total params: 532,930
Trainable params: 532,930
Non-trainable params: 0
________________________________________________________________

Adding in a .5 dropout to each layer just meant that it took longer to train. It still doesn't break 90% in the validation.
Overtraining is the problem, and it's not in the first layer, it's in the whole thing. I haven't added in regularization,
which could theoretically help, but I'm frustrated that I can't imporve the validation at all._
