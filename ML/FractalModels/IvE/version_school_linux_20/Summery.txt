Seed: 3268734

Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 64, 64, 4)]       0         
                                                                 
 conv2d (Conv2D)             (None, 64, 64, 64)        320       
                                                                 
 dropout (Dropout)           (None, 64, 64, 64)        0         
                                                                 
 conv2d_1 (Conv2D)           (None, 64, 64, 64)        4160      
                                                                 
 dropout_1 (Dropout)         (None, 64, 64, 64)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 64, 64, 64)        4160      
                                                                 
 dropout_2 (Dropout)         (None, 64, 64, 64)        0         
                                                                 
 flatten (Flatten)           (None, 262144)            0         
                                                                 
 dense (Dense)               (None, 2)                 524290    
                                                                 
=================================================================
Total params: 532,930
Trainable params: 532,930
Non-trainable params: 0
_________________________________________________________________


input_layer = tf.keras.Input(shape = (64, 64, 4))
x = tf.keras.layers.Conv2D(64, (1, 1), activation = "gelu", kernel_regularizer = tf.keras.regularizers.l2(l = 0.001))(input_layer)
x = tf.keras.layers.Dropout(.25)(x)
x = tf.keras.layers.Conv2D(64, (1, 1), activation = "gelu", kernel_regularizer = tf.keras.regularizers.l2(l = 0.001))(x)
x = tf.keras.layers.Dropout(.25)(x)
x = tf.keras.layers.Conv2D(64, (1, 1), activation = "gelu", kernel_regularizer = tf.keras.regularizers.l2(l = 0.001))(x)
x = tf.keras.layers.Dropout(.25)(x)
x = tf.keras.layers.Flatten()(x)
output_layer = tf.keras.layers.Dense(output_classes, activation = "softmax")(x)

model = tf.keras.Model(inputs = input_layer, outputs = output_layer)

model.compile(optimizer = 'adam',
              loss = 'categorical_crossentropy',
              #   metrics = ['accuracy'])
              metrics = [tf.keras.metrics.CategoricalAccuracy()])


This increased the accruacy of the training, but not the validation. This means that there is probably another layer that can be added BUT
it's overtraining. So I have to figure out how to now overtrain it. I may also need to introduce batch normalization and increase drop outs.